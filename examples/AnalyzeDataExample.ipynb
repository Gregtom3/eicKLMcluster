{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d765e87-7bd3-4398-a617-e2eaccc2a184",
   "metadata": {},
   "source": [
    "# Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c31dcb3-3998-49a3-85ff-5b8045e386f6",
   "metadata": {},
   "source": [
    "**Requirements**: You might need to make a venv and install Ipython and setup use in jupyternotebook (see here for help: https://www.geeksforgeeks.org/using-jupyter-notebook-in-virtual-environment/)\n",
    "\n",
    "**Download** the NF timing param model and put it in the folder \"examples/NF_model\" from the duke box\n",
    "\n",
    "**Needed packages**: normalizing-flows, torch,numpy,pandas,uproot\n",
    "may also need to install basic stuff: os, tqdm, time, matplotlib, tracemalloc, linecache, \n",
    "\n",
    "**Note**: the analysis code does not need to use ROOT - however, the processing code (not shown here) does, so if you want to run that you need pyroot or eicshell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fd2c26-9023-40ff-9402-85ac7efb6365",
   "metadata": {},
   "source": [
    "### This notebook contains the code to run the data analysis, but all of the functions are in util.py to keep things (a little) organized\n",
    "\n",
    "### If you want to debug specific functions, feel free to copy and paste them here rather than importing them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b775c4-fc66-45c0-a61b-5316d3e351c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:08:56 began analyze_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/normflows/core.py:213: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:08:58 Processing data in generateSiPMOutput...\n",
      "13:09:00 starting sampling\n",
      "13:09:00 Starting batch # 1.0 / 3\n",
      "13:09:00 Starting batch # 2.0 / 3\n",
      "13:09:01 Starting batch # 3.0 / 3\n",
      "13:09:01 sampling took 0.029230237007141113 minutes\n",
      "13:09:01 creating df\n",
      "13:09:10 Beginning pulse process\n",
      "         90214248 function calls (89406655 primitive calls) in 239.321 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 617 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1   10.048   10.048  239.321  239.321 /hpc/group/vossenlab/rck32/eic/eicKLMcluster/examples/util.py:266(generateSiPMOutput)\n",
      "   384784    2.234    0.000  144.579    0.000 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/groupby/ops.py:607(get_iterator)\n",
      "   128260    0.440    0.000   93.706    0.001 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/groupby/ops.py:622(_get_splitter)\n",
      "   128260    0.210    0.000   90.285    0.001 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/groupby/ops.py:743(group_info)\n",
      "   128260    0.558    0.000   90.061    0.001 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/groupby/ops.py:758(_get_compressed_codes)\n",
      "   256524    2.606    0.000   87.703    0.000 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/groupby/groupby.py:1217(<genexpr>)\n",
      "   128267    0.144    0.000   71.250    0.001 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/groupby/grouper.py:689(codes)\n",
      "   128263    0.298    0.000   71.106    0.001 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/groupby/grouper.py:777(_codes_and_uniques)\n",
      "   128263    1.008    0.000   70.792    0.001 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/algorithms.py:610(factorize)\n",
      "   128263    1.891    0.000   48.797    0.000 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/algorithms.py:1452(safe_sort)\n",
      "        2    0.000    0.000   48.433   24.217 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/groupby/ops.py:687(codes)\n",
      "        2    0.000    0.000   48.433   24.217 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/groupby/ops.py:690(<listcomp>)\n",
      "   384784    5.168    0.000   44.158    0.000 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/groupby/ops.py:1149(__iter__)\n",
      "   384690   42.017    0.000   42.017    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "   384793    2.106    0.000   29.680    0.000 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/frame.py:4062(__getitem__)\n",
      "   128260    1.062    0.000   25.339    0.000 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/frame.py:9041(groupby)\n",
      "   384793    1.822    0.000   25.305    0.000 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/frame.py:4626(_get_item_cache)\n",
      "   128260    1.151    0.000   24.277    0.000 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/groupby/groupby.py:1296(__init__)\n",
      "   128260    0.270    0.000   23.478    0.000 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/groupby/ops.py:1162(_sorted_data)\n",
      "   128260    1.373    0.000   23.208    0.000 /hpc/group/vossenlab/rck32/ML_venv/lib64/python3.9/site-packages/pandas/core/generic.py:4027(take)\n",
      "\n",
      "\n",
      "\n",
      "13:13:02 generateSiPMOutput took 4.068884853521983 minutes\n",
      "13:13:02 finished job\n",
      "13:13:02 analyzing memory snapshot\n",
      "Top 3 lines\n",
      "#1: <frozen importlib._bootstrap_external>:647: 29609.8 KiB\n",
      "#2: hipify/hipify_python.py:683: 8760.7 KiB\n",
      "    node.children.setdefault(char, TrieNode())\n",
      "#3: hipify/hipify_python.py:668: 7434.8 KiB\n",
      "    self.children = {}\n",
      "42138 other: 41117.8 KiB\n",
      "Total allocated size: 86923.0 KiB\n"
     ]
    }
   ],
   "source": [
    "from util import print_w_time, get_compiled_NF_model,generateSiPMOutput,display_top\n",
    "import uproot\n",
    "import numpy as np\n",
    "from  torch import device as torchdevice\n",
    "from torch.cuda import is_available as torchcudaisavailable\n",
    "import matplotlib.pyplot as plot\n",
    "import time\n",
    "# Get device to be used\n",
    "device = torchdevice('cuda' if torchcudaisavailable() else 'cpu')\n",
    "from os.path import exists as ospathexists\n",
    "from os import makedirs as osmakedirs\n",
    "def checkdir(path):\n",
    "    if not ospathexists(path): \n",
    "        osmakedirs(path)\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from  pandas import read_csv as pd_read_csv\n",
    "\n",
    "print_w_time(\"began analyze_data\")\n",
    "outputDataframePathName = \"dfs/test_output.csv\"\n",
    "inputProcessedData = \"dfs/test_data_from_processing.csv\"\n",
    "\n",
    "\n",
    "'''MEMORY PROFILING'''\n",
    "import linecache\n",
    "import os\n",
    "import tracemalloc\n",
    "\n",
    "tracemalloc.start()\n",
    "    \n",
    "'''MEMORY PROFILING SETUP END'''\n",
    "model_path = \"./NF_model/run_7_3context_8flows_26hl_256hu_2000bs.pth\"\n",
    "model_compile = get_compiled_NF_model(model_path) #load timing param model\n",
    "processed_data = pd_read_csv(inputProcessedData) #open input csv\n",
    "begin = time.time()\n",
    "df = generateSiPMOutput(processed_data, model_compile,batch_size = 50000) #analyze data\n",
    "\n",
    "df.to_csv(outputDataframePathName) #save output (this is the clustering input)\n",
    "end = time.time()\n",
    "print_w_time(f\"generateSiPMOutput took {(end - begin) / 60} minutes\")\n",
    "print_w_time(\"finished job\")\n",
    "print_w_time(\"analyzing memory snapshot\")\n",
    "\n",
    "snapshot = tracemalloc.take_snapshot() #some memory profiling can be useful\n",
    "display_top(snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb075e-bad9-4743-a755-7a77ab43c9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_venv",
   "language": "python",
   "name": "ml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
